**USER:**
can you provide model configs for gpt 5.2 and gpt-codex 5.2, 5.1 and 5. codex and gpt to have max and extra max reasoning with highest thinking tokens? give me in json format. 

---
**GPT 5.2 Extended Thinking:**

Below are **copy/paste JSON request bodies** for both **Responses API** and **Chat Completions API**, tuned for **max token budget** and **highest reasoning effort the model supports** (where supported). `max_output_tokens` / `max_completion_tokens` count **visible output + reasoning (“thinking”) tokens**. ([OpenAI Platform][1])

```json
{
  "presets": {
    "gpt-5.2": {
      "responses_api": {
        "max_reasoning": {
          "model": "gpt-5.2",
          "reasoning": { "effort": "high" },
          "max_output_tokens": 128000,
          "temperature": 0,
          "top_p": 1,
          "input": "<YOUR PROMPT HERE>"
        },
        "extra_max_reasoning": {
          "model": "gpt-5.2",
          "reasoning": { "effort": "xhigh" },
          "max_output_tokens": 128000,
          "background": true,
          "temperature": 0,
          "top_p": 1,
          "input": "<YOUR PROMPT HERE>"
        }
      },
      "chat_completions_api": {
        "max_reasoning": {
          "model": "gpt-5.2",
          "reasoning_effort": "high",
          "max_completion_tokens": 128000,
          "temperature": 0,
          "top_p": 1,
          "messages": [{ "role": "user", "content": "<YOUR PROMPT HERE>" }]
        },
        "extra_max_reasoning": {
          "model": "gpt-5.2",
          "reasoning_effort": "xhigh",
          "max_completion_tokens": 128000,
          "temperature": 0,
          "top_p": 1,
          "messages": [{ "role": "user", "content": "<YOUR PROMPT HERE>" }]
        }
      }
    },

    "gpt-5.1": {
      "responses_api": {
        "max_reasoning": {
          "model": "gpt-5.1",
          "reasoning": { "effort": "high" },
          "max_output_tokens": 128000,
          "temperature": 0,
          "top_p": 1,
          "input": "<YOUR PROMPT HERE>"
        },
        "extra_max_reasoning": {
          "model": "gpt-5.1",
          "reasoning": { "effort": "high" },
          "max_output_tokens": 128000,
          "background": true,
          "temperature": 0,
          "top_p": 1,
          "input": "<YOUR PROMPT HERE>"
        }
      },
      "chat_completions_api": {
        "max_reasoning": {
          "model": "gpt-5.1",
          "reasoning_effort": "high",
          "max_completion_tokens": 128000,
          "temperature": 0,
          "top_p": 1,
          "messages": [{ "role": "user", "content": "<YOUR PROMPT HERE>" }]
        },
        "extra_max_reasoning": {
          "model": "gpt-5.1",
          "reasoning_effort": "high",
          "max_completion_tokens": 128000,
          "temperature": 0,
          "top_p": 1,
          "messages": [{ "role": "user", "content": "<YOUR PROMPT HERE>" }]
        }
      }
    },

    "gpt-5": {
      "responses_api": {
        "max_reasoning": {
          "model": "gpt-5",
          "reasoning": { "effort": "high" },
          "max_output_tokens": 128000,
          "temperature": 0,
          "top_p": 1,
          "input": "<YOUR PROMPT HERE>"
        },
        "extra_max_reasoning": {
          "model": "gpt-5",
          "reasoning": { "effort": "high" },
          "max_output_tokens": 128000,
          "background": true,
          "temperature": 0,
          "top_p": 1,
          "input": "<YOUR PROMPT HERE>"
        }
      },
      "chat_completions_api": {
        "max_reasoning": {
          "model": "gpt-5",
          "reasoning_effort": "high",
          "max_completion_tokens": 128000,
          "temperature": 0,
          "top_p": 1,
          "messages": [{ "role": "user", "content": "<YOUR PROMPT HERE>" }]
        },
        "extra_max_reasoning": {
          "model": "gpt-5",
          "reasoning_effort": "high",
          "max_completion_tokens": 128000,
          "temperature": 0,
          "top_p": 1,
          "messages": [{ "role": "user", "content": "<YOUR PROMPT HERE>" }]
        }
      }
    },

    "gpt-5.2-codex": {
      "responses_api": {
        "max_reasoning": {
          "model": "gpt-5.2-codex",
          "reasoning": { "effort": "high" },
          "max_output_tokens": 128000,
          "temperature": 0,
          "top_p": 1,
          "input": "<YOUR PROMPT HERE>"
        },
        "extra_max_reasoning": {
          "model": "gpt-5.2-codex",
          "reasoning": { "effort": "xhigh" },
          "max_output_tokens": 128000,
          "background": true,
          "temperature": 0,
          "top_p": 1,
          "input": "<YOUR PROMPT HERE>"
        }
      },
      "chat_completions_api": {
        "max_reasoning": {
          "model": "gpt-5.2-codex",
          "reasoning_effort": "high",
          "max_completion_tokens": 128000,
          "temperature": 0,
          "top_p": 1,
          "messages": [{ "role": "user", "content": "<YOUR PROMPT HERE>" }]
        },
        "extra_max_reasoning": {
          "model": "gpt-5.2-codex",
          "reasoning_effort": "xhigh",
          "max_completion_tokens": 128000,
          "temperature": 0,
          "top_p": 1,
          "messages": [{ "role": "user", "content": "<YOUR PROMPT HERE>" }]
        }
      }
    },

    "gpt-5.1-codex": {
      "responses_api": {
        "max_reasoning": {
          "model": "gpt-5.1-codex",
          "reasoning": { "effort": "high" },
          "max_output_tokens": 128000,
          "temperature": 0,
          "top_p": 1,
          "input": "<YOUR PROMPT HERE>"
        },
        "extra_max_reasoning": {
          "model": "gpt-5.1-codex",
          "reasoning": { "effort": "high" },
          "max_output_tokens": 128000,
          "background": true,
          "temperature": 0,
          "top_p": 1,
          "input": "<YOUR PROMPT HERE>"
        }
      },
      "chat_completions_api": {
        "max_reasoning": {
          "model": "gpt-5.1-codex",
          "reasoning_effort": "high",
          "max_completion_tokens": 128000,
          "temperature": 0,
          "top_p": 1,
          "messages": [{ "role": "user", "content": "<YOUR PROMPT HERE>" }]
        },
        "extra_max_reasoning": {
          "model": "gpt-5.1-codex",
          "reasoning_effort": "high",
          "max_completion_tokens": 128000,
          "temperature": 0,
          "top_p": 1,
          "messages": [{ "role": "user", "content": "<YOUR PROMPT HERE>" }]
        }
      }
    },

    "gpt-5-codex": {
      "responses_api": {
        "max_reasoning": {
          "model": "gpt-5-codex",
          "reasoning": { "effort": "high" },
          "max_output_tokens": 128000,
          "temperature": 0,
          "top_p": 1,
          "input": "<YOUR PROMPT HERE>"
        },
        "extra_max_reasoning": {
          "model": "gpt-5-codex",
          "reasoning": { "effort": "high" },
          "max_output_tokens": 128000,
          "background": true,
          "temperature": 0,
          "top_p": 1,
          "input": "<YOUR PROMPT HERE>"
        }
      },
      "chat_completions_api": {
        "max_reasoning": {
          "model": "gpt-5-codex",
          "reasoning_effort": "high",
          "max_completion_tokens": 128000,
          "temperature": 0,
          "top_p": 1,
          "messages": [{ "role": "user", "content": "<YOUR PROMPT HERE>" }]
        },
        "extra_max_reasoning": {
          "model": "gpt-5-codex",
          "reasoning_effort": "high",
          "max_completion_tokens": 128000,
          "temperature": 0,
          "top_p": 1,
          "messages": [{ "role": "user", "content": "<YOUR PROMPT HERE>" }]
        }
      }
    }
  }
}
```

Sources for (a) which models support `xhigh` and (b) what “max tokens” counts: GPT-5.2 supports `reasoning.effort` up to `xhigh` ([OpenAI Platform][2]); GPT-5.1 supports up to `high` ([OpenAI Platform][3]); GPT-5 supports up to `high` ([OpenAI Platform][4]); GPT-5.2-Codex supports `xhigh` ([OpenAI Platform][5]); `max_output_tokens` / `max_completion_tokens` include reasoning (“thinking”) tokens ([OpenAI Platform][1]); chat `reasoning_effort` value set and model-specific support notes ([OpenAI Platform][6]).

[1]: https://platform.openai.com/docs/api-reference/responses "Responses | OpenAI API Reference"
[2]: https://platform.openai.com/docs/models/gpt-5.2 "GPT-5.2 Model | OpenAI API"
[3]: https://platform.openai.com/docs/models/gpt-5.1 "GPT-5.1 Model | OpenAI API"
[4]: https://platform.openai.com/docs/models/gpt-5 "GPT-5 Model | OpenAI API"
[5]: https://platform.openai.com/docs/models/gpt-5.2-codex "GPT-5.2-Codex Model | OpenAI API"
[6]: https://platform.openai.com/docs/api-reference/chat "Chat Completions | OpenAI API Reference"
